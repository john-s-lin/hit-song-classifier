# Hit Song Classifier - Using the Million Song Dataset and Billboard to Predict Song Rankings

What constitutes a "hit" song, worthy enough to be placed on the widely popular Billboard Hot 100 list? Here, we seek to correlate song attributes from the Million Song dataset and the Billboard Hot 100 list to predict the range of rankings that a song might fall under.

Songs will be classified along 11 ordinal buckets that characterize the range of rankings, with classes 0-9 representing the Hot 100 rankings equally subdivided into 10 groups. Note that class 10 represents all songs that are unranked or have a rank exceeding 100. From the Million Song dataset, we will focus on these attributes: `artist_name, title` and `year` to identify a unique song, and `danceability, duration, energy, key, loudness, song_hotness, tempo` and `time_signature` as features we considered most important. These features were chosen since they encompass most of a song's "quality". 

From the Billboard Hot 100 we will use `artist, title` for song identification, and `rank` to identify the class that a song belongs to. However, a confounding factor is that since Billboard publishes a new Hot 100 ranking weekly, songs may appear on the list multiple times and thus have multiple ranks. We therefore intend on using a song's best ranking, whittling down multiple rankings to one. The raw data will be preprocessed such that a song's best rank will correlate with a class. For example, a song that is ranked 5 will be placed in class 0, while a song that is ranked 73 will be placed in class 7.

As this is a classification problem, we will be comparing the performance of two classification machine learning models: Random Forest Classifiers (RFCs) and Support Vector Machines (SVMs). RFCs were chosen as an ensemble model of Decision Trees, being fairly accurate and relatively quick to train while also being less prone to overfitting. Similarly, SVMs are also accurate, and require only supporting vectors to define a separating hyperplane between multiple classes. However, SVMs take longer to train. We intend on using a 60-20-20 split for training, validation, and test subsets from our dataset. Finally, we will tune our models with hyperparameter search and k-fold cross-validation.

This sets the stage for potential further studies that can be pursued, such as using other classification models like k-nearest neighbours or gradient boost, using regression models to predict a song's exact ranking, or adding features such as sentiment analysis on a song's lyrics.
